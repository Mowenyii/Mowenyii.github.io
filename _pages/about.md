---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

<!-- I'm a in-coming phd student at Rutgers University, where I am advised by Prof. [Dimitris N. Metaxas](https://people.cs.rutgers.edu/~dnm/) I got master degree at [Renmin University of China](http://ai.ruc.edu.cn/english/index.htm), where I am advised by [Bing Su](https://gsai.ruc.edu.cn/english/bingsu). I earned my B.E. from South China University of Technology. My research focuses on multimodal learning, particularly enhancing user alignment and image controllability in generative models. Recently, Iâ€™ve worked on autoregressive and diffusion models, exploring applications like text-to-image generation and preference alignment. You can view my CV [here](https://mowenyii.github.io/files/Wenyi_Mo.pdf). -->

<!-- > I am always open for research discussions and collaborations :). Also, I am looking for a potential Ph.D. position enrolling in Fall 2025. Welcome to reach out to me if interested. -->

<!-- , and earned my B.E. from the South China University of Technology -->

I am a first-year Ph.D. student at [Rutgers University](https://www.rutgers.edu/), where I am advised by [Prof. Dimitris N. Metaxas](https://people.cs.rutgers.edu/~dnm/). I received my Masterâ€™s degree from the [Renmin University of China](http://ai.ruc.edu.cn/english/index.htm), advised by [Prof. Bing Su](https://gsai.ruc.edu.cn/english/bingsu).
My research interests lie in multimodal learning, with a focus on enhancing user alignment and image controllability in generative models. Recently, Iâ€™ve been working with autoregressive and diffusion models, particularly in the context of text-to-image generation and preference alignment.
<!-- You can find my CV [here](https://mowenyii.github.io/files/Wenyi_Mo.pdf). -->





# ğŸ”¥ News
- *06/2025*: ğŸ‰ [One co-authored paper](https://github.com/BarretBa/ICTHP) about Text-to-Image generation accepted to ICCV 2025.
- *01/2025*: ğŸ‰ One co-authored paper about vision-language models accepted to NeuralÂ Networks 2025.
- *11/2024*: ğŸ‰ Recognized as a [top reviewer at NeurIPS 2024](https://neurips.cc/Conferences/2024/ProgramCommittee#top-reviewers).
- *10/2024*: ğŸ‰ One first-authored paper about image editing accepted to WACV 2025.
- *02/2024*: ğŸ‰ One first-authored paper about Text-to-Image generation accepted to CVPR 2024.
- *09/2022*: ğŸ‰ One co-authored paper accepted to NeurIPS 2022.



# ğŸ“ Publications 






<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/DF_example.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Dynamic Prompt Optimizing for Text-to-Image Generation](https://openaccess.thecvf.com/content/CVPR2024/papers/Mo_Dynamic_Prompt_Optimizing_for_Text-to-Image_Generation_CVPR_2024_paper.pdf)

**Wenyi Mo**, Tianyu Zhang, Yalong Bai, Bing Su<sup>âœ‰</sup>, Ji-Rong Wen, Qing Yang. 

<span style="color:red">(CVPR 2024)</span>  [![](https://img.shields.io/github/stars/Mowenyii/PAE?style=social&label=Code+Stars)](https://github.com/Mowenyii/PAE)

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2025</div><img src='images/ICCV25-2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Enhancing Reward Models for High-quality Image Generation: Beyond Text-Image Alignment](https://arxiv.org/abs/2507.19002)

Ying Ba, Tianyu Zhang, Yalong Bai, **Wenyi Mo**, Tao Liang, Bing Su, Ji-Rong Wen. 

<span style="color:red">(ICCV 2025)</span>  [![](https://img.shields.io/github/stars/BarretBa/ICTHP?style=social&label=Code+Stars)](https://github.com/BarretBa/ICTHP) 


</div>
</div>


<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">Under Review</div><img src='images/under_review.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[User-Specific Preference Prediction on Generated Images](https://mowenyii.github.io/files/25_wenyi_arxiv.pdf)

**Wenyi Mo**, Tianyu Zhang, Yalong Bai, Jieqiong Liu, Bing Su<sup>âœ‰</sup>, Biye Li, Ji-Rong Wen. 

</div>
</div> -->

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">WACV 2025</div><img src='images/wacv.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Uniform Attention Maps: Boosting Image Fidelity in Reconstruction and Editing](https://arxiv.org/abs/2411.19652)

**Wenyi Mo**, Tianyu Zhang, Yalong Bai, Bing Su<sup>âœ‰</sup>, Ji-Rong Wen. 

<span style="color:red">(WACV 2025)</span>  [![](https://img.shields.io/github/stars/Mowenyii/Uniform-Attention-Maps?style=social&label=Code+Stars)](https://github.com/Mowenyii/Uniform-Attention-Maps) 


</div>
</div>

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">NN 2025</div><img src='images/nn25_CPKP.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Supporting Vision-Language Model Few-Shot Inference with Confounder-Pruned knowledge Prompt](https://papers.ssrn.com/sol3/Delivery.cfm?abstractid=4909583)

Jiangmeng Li, **Wenyi Mo**, Fei Song, Chuxiong Sun, Wenwen Qiang, Bing Su, and Changwen Zheng. 

<span style="color:red">(NeuralÂ Networks 2025)</span>  [![](https://img.shields.io/github/stars/Mowenyii/CPKP?style=social&label=Code+Stars)](https://github.com/Mowenyii/CPKP) 


</div>
</div> -->



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2022</div><img src='images/neurips22.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[MetaMask: Revisiting Dimensional Confounder for Self-Supervised Learning](https://papers.neurips.cc/paper_files/paper/2022/file/fb575ab4d882a4c734641155a5f30911-Paper-Conference.pdf)

 Jiangmeng Li\*, Wenwen Qiang\*, Yanan Zhang, **Wenyi Mo**, Changwen Zheng, Bing Su<sup>âœ‰</sup>, and Hui Xiong. 
 
  <span style="color:red">(NeurIPS 2022, Spotlight)</span>  [![](https://img.shields.io/github/stars/jiangmengli/metamask?style=social&label=Code+Stars)](https://github.com/jiangmengli/metamask)

</div>
</div>


# ğŸ‘©â€ğŸ« Invited Talks
- *10/2025*, Poster Presentation @ ICCV Honolulu, HawaiÊ»i. 
- *06/2024*, Poster Presentation @ CVPR Seattle, Washington. 

# ğŸ– Honors and Awards
- *10/2024*, Merit Graduated Student of Renmin University of China.
- *10/2024*, Renmin University of China Scholarship. 
- *12/2021*, China National Encouragement Scholarship, (Top 3%). 
- *12/2019*, China National Scholarship, (Top 1%). 


# ğŸ‘©â€ğŸ’» Academic Services
- Conference Reviewer: NeurIPS (2024, 2025), ICLR (2025, 2026), AISTATS (2025, 2026), CVPR (2025, 2026), WACV 2025,  ICML 2025, ICCV 2025, AAAI 2026.
<!-- - Journal Reviewer: Scientific Reports -->

<!-- # ğŸ“– Educations
- *08/2022 - 06/2025*, Master, Department of  Artificial Intelligence, Renmin University of China, Beijing.
- *08/2018 - 06/2022*, Undergraduate, Department of Computer Science, South China University of Technology, Guangzhou. -->



# ğŸ’» Internships
- *03/2024 - 09/2025*, In2X, Beijing, China.
- *01/2024 - 03/2024*, Bytedance Seed, Shanghai, China.
- *09/2023 - 01/2024*, Du Xiaoman Technology, Beijing, China.
- *01/2022 - 03/2022*, Jingdong Exploration Research Institute, Beijing, China.

<!-- # ğŸšŒ Visitor Map -->
<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=1nRIFNSwVclwApwJhz16pZZAjy8G47awU92Eq0b1mQ8"></script>
